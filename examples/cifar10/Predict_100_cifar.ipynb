{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on 1 image to make sure the network is tied together correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1. Load the trained network weights\n",
    "#2. Run the net forward and get an array of predictions\n",
    "#3. Compare the result to the label\n",
    "\n",
    "using Mocha, Images, ImageView, Colors, HDF5, MLBase\n",
    "backend = CPUBackend()\n",
    "init(backend)\n",
    "\n",
    "image_x = 32\n",
    "image_y = 32\n",
    "image_depth = 3\n",
    "\n",
    "test_index = 6;\n",
    "\n",
    "#Create a memory data layer in the prediction model that we computation\n",
    "#sequentially tie to the next image we want to predict on.\n",
    "mem_data = MemoryDataLayer(name=\"data\", tops=[:data], batch_size=1,\n",
    "    data=Array[zeros(Float32, image_x, image_y, image_depth, 1)])\n",
    "\n",
    "#Copy over the rest of the layers from the training network\n",
    "conv1_layer = ConvolutionLayer(name=\"conv1\", n_filter=32, kernel=(5,5), pad=(2,2),\n",
    "    stride=(1,1), filter_init=GaussianInitializer(std=0.0001),\n",
    "    bottoms=[:data], tops=[:conv1])\n",
    "pool1_layer = PoolingLayer(name=\"pool1\", kernel=(3,3), stride=(2,2), neuron=Neurons.ReLU(),\n",
    "    bottoms=[:conv1], tops=[:pool1])\n",
    "norm1_layer = LRNLayer(name=\"norm1\", kernel=3, scale=5e-5, power=0.75, mode=LRNMode.WithinChannel(),\n",
    "    bottoms=[:pool1], tops=[:norm1])\n",
    "conv2_layer = ConvolutionLayer(name=\"conv2\", n_filter=32, kernel=(5,5), pad=(2,2),\n",
    "    stride=(1,1), filter_init=GaussianInitializer(std=0.01),\n",
    "    bottoms=[:norm1], tops=[:conv2], neuron=Neurons.ReLU())\n",
    "pool2_layer = PoolingLayer(name=\"pool2\", kernel=(3,3), stride=(2,2), pooling=Pooling.Mean(),\n",
    "    bottoms=[:conv2], tops=[:pool2])\n",
    "norm2_layer = LRNLayer(name=\"norm2\", kernel=3, scale=5e-5, power=0.75, mode=LRNMode.WithinChannel(),\n",
    "    bottoms=[:pool2], tops=[:norm2])\n",
    "conv3_layer = ConvolutionLayer(name=\"conv3\", n_filter=64, kernel=(5,5), pad=(2,2),\n",
    "    stride=(1,1), filter_init=GaussianInitializer(std=0.01),\n",
    "    bottoms=[:norm2], tops=[:conv3], neuron=Neurons.ReLU())\n",
    "pool3_layer = PoolingLayer(name=\"pool3\", kernel=(3,3), stride=(2,2), pooling=Pooling.Mean(),\n",
    "    bottoms=[:conv3], tops=[:pool3])\n",
    "ip1_layer   = InnerProductLayer(name=\"ip1\", output_dim=10, weight_init=GaussianInitializer(std=0.01),\n",
    "    weight_regu=L2Regu(250), bottoms=[:pool3], tops=[:ip1])\n",
    "\n",
    "#Instead of a SoftmaxLossLayer like the training script in this file we\n",
    "#have a pure SoftmaxLayer in order to determine the probability of the \n",
    "#image compared against the different n classification options\n",
    "softmax_layer = SoftmaxLayer(name=\"prob\", tops=[:prob], bottoms=[:ip1])\n",
    "\n",
    "#Build the network\n",
    "common_layers = [conv1_layer, pool1_layer, norm1_layer, conv2_layer, pool2_layer, norm2_layer,\n",
    "                 conv3_layer, pool3_layer, ip1_layer]\n",
    "run_net = Net(\"imagenet\", backend, [mem_data, common_layers..., softmax_layer])\n",
    "\n",
    "#Load the network snapshot from the training data\n",
    "load_snapshot(run_net, \"snapshots/snapshot-070000.jld\")\n",
    "\n",
    "#Now run one test through the network to ensure it is set up correctly\n",
    "fid = h5open(\"cifar_data/test.hdf5\", \"r\")\n",
    "features = read(fid, \"data\")\n",
    "labels = read(fid, \"label\")\n",
    "\n",
    "get_layer(run_net, \"data\").data[1][:,:,image_depth,1] = features[:,:,image_depth,test_index]\n",
    "\n",
    "offset = 1  #my tags vector is 1-indexed but the labels vector is \n",
    "            #is 0-indexed.  So I have to add an offset of 1 to the label value to \n",
    "            # match my predictive value \n",
    "println(\"\\nCorrect label index: \", Int64(labels[test_index])+offset)\n",
    "\n",
    "forward(run_net)\n",
    "println()\n",
    "println(\"Label prob vector:\")\n",
    "println(run_net.output_blobs[:prob].data)\n",
    "\n",
    "# Use MLBase to classify the output blob\n",
    "\n",
    "prediction = classify(run_net.output_blobs[:prob].data)\n",
    "println(\"Prediction is: \", prediction[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on 1 with visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1. Load the trained network weights\n",
    "#2. Run the net forward and get an array of predictions\n",
    "#3. Use MLBase to classify the prediction\n",
    "#4. Load the tags and GT labels\n",
    "#5. Use the tags and GT to annotate the image\n",
    "\n",
    "using Mocha, Images, ImageView, Colors, HDF5, MLBase\n",
    "backend = CPUBackend()\n",
    "init(backend)\n",
    "\n",
    "image_x = 32\n",
    "image_y = 32\n",
    "image_depth = 3\n",
    "\n",
    "test_index = 12;\n",
    "\n",
    "#Create a memory data layer in the prediction model that we computation\n",
    "#sequentially tie to the next image we want to predict on.\n",
    "mem_data = MemoryDataLayer(name=\"data\", tops=[:data], batch_size=1,\n",
    "    data=Array[zeros(Float32, image_x, image_y, image_depth, 1)])\n",
    "\n",
    "#Copy over the rest of the layers from the training network\n",
    "conv1_layer = ConvolutionLayer(name=\"conv1\", n_filter=32, kernel=(5,5), pad=(2,2),\n",
    "    stride=(1,1), filter_init=GaussianInitializer(std=0.0001),\n",
    "    bottoms=[:data], tops=[:conv1])\n",
    "pool1_layer = PoolingLayer(name=\"pool1\", kernel=(3,3), stride=(2,2), neuron=Neurons.ReLU(),\n",
    "    bottoms=[:conv1], tops=[:pool1])\n",
    "norm1_layer = LRNLayer(name=\"norm1\", kernel=3, scale=5e-5, power=0.75, mode=LRNMode.WithinChannel(),\n",
    "    bottoms=[:pool1], tops=[:norm1])\n",
    "conv2_layer = ConvolutionLayer(name=\"conv2\", n_filter=32, kernel=(5,5), pad=(2,2),\n",
    "    stride=(1,1), filter_init=GaussianInitializer(std=0.01),\n",
    "    bottoms=[:norm1], tops=[:conv2], neuron=Neurons.ReLU())\n",
    "pool2_layer = PoolingLayer(name=\"pool2\", kernel=(3,3), stride=(2,2), pooling=Pooling.Mean(),\n",
    "    bottoms=[:conv2], tops=[:pool2])\n",
    "norm2_layer = LRNLayer(name=\"norm2\", kernel=3, scale=5e-5, power=0.75, mode=LRNMode.WithinChannel(),\n",
    "    bottoms=[:pool2], tops=[:norm2])\n",
    "conv3_layer = ConvolutionLayer(name=\"conv3\", n_filter=64, kernel=(5,5), pad=(2,2),\n",
    "    stride=(1,1), filter_init=GaussianInitializer(std=0.01),\n",
    "    bottoms=[:norm2], tops=[:conv3], neuron=Neurons.ReLU())\n",
    "pool3_layer = PoolingLayer(name=\"pool3\", kernel=(3,3), stride=(2,2), pooling=Pooling.Mean(),\n",
    "    bottoms=[:conv3], tops=[:pool3])\n",
    "ip1_layer   = InnerProductLayer(name=\"ip1\", output_dim=10, weight_init=GaussianInitializer(std=0.01),\n",
    "    weight_regu=L2Regu(250), bottoms=[:pool3], tops=[:ip1])\n",
    "\n",
    "#Instead of a SoftmaxLossLayer like the training script in this file we\n",
    "#have a pure SoftmaxLayer in order to determine the probability of the \n",
    "#image compared against the different n classification options\n",
    "softmax_layer = SoftmaxLayer(name=\"prob\", tops=[:prob], bottoms=[:ip1])\n",
    "\n",
    "#Build the network\n",
    "common_layers = [conv1_layer, pool1_layer, norm1_layer, conv2_layer, pool2_layer, norm2_layer,\n",
    "                 conv3_layer, pool3_layer, ip1_layer]\n",
    "run_net = Net(\"imagenet\", backend, [mem_data, common_layers..., softmax_layer])\n",
    "\n",
    "#Load the network snapshot from the training data\n",
    "load_snapshot(run_net, \"snapshots/snapshot-070000.jld\")\n",
    "\n",
    "#Now run one test through the network to ensure it is set up correctly\n",
    "fid = h5open(\"cifar_data/test.hdf5\", \"r\")\n",
    "features = read(fid, \"data\")\n",
    "labels = read(fid, \"label\")\n",
    "\n",
    "get_layer(run_net, \"data\").data[1][:,:,image_depth,1] = features[:,:,image_depth,test_index]\n",
    "\n",
    "#read the meta_labels file\n",
    "tags = []\n",
    "fname = \"batches.meta.txt\"\n",
    "open(fname) do file\n",
    "    for line in eachline(file)\n",
    "        line = strip(line)\n",
    "        if length(line)>0 \n",
    "            push!(tags, strip(line))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "offset = 1  #my tags vector is 1-indexed but the labels vector is \n",
    "            #is 0-indexed.  So I have to add an offset of 1 to the label value to \n",
    "            # match my predictive value \n",
    "gt = Int64(labels[test_index])+offset\n",
    "println(\"Ground truth label: \", gt, \"-\",tags[gt])\n",
    "\n",
    "\n",
    "# Run the net forward and use MLBase to classify the output blob\n",
    "forward(run_net)\n",
    "prediction = classify(run_net.output_blobs[:prob].data)\n",
    "println(\"Prediction is:      \", prediction[1], \"-\", tags[prediction[1]])\n",
    "\n",
    "# Load and annotate the image\n",
    "#read the image and label data files\n",
    "vis_fid = h5open(\"cifar_data/visual.hdf5\", \"r\")\n",
    "vis_data = read(vis_fid, \"data\")\n",
    "image = test_index\n",
    "\n",
    "#create the image\n",
    "img = convert(Image, vis_data[:,:,:,image])\n",
    "img[\"spatialorder\"]=[\"x\",\"y\"]\n",
    "\n",
    "#create the string label\n",
    "l1 = string(\"GT: \", tags[gt])\n",
    "l2 = string(\"Pred: \", tags[prediction[1]])\n",
    "\n",
    "#set up the label location on the 32x32 image\n",
    "x1 = 4\n",
    "y1 = 30\n",
    "x2 = 4\n",
    "y2 = 3\n",
    "\n",
    "#annotate the image\n",
    "imgc, imgslice = ImageView.view(img);\n",
    "idx = ImageView.annotate!(imgc, imgslice, ImageView.AnnotationText(x1, y1, l1, color=RGB(1,1,1), fontsize=2, halign=\"left\"))\n",
    "idx = ImageView.annotate!(imgc, imgslice, ImageView.AnnotationText(x2, y2, l2, color=RGB(1,1,1), fontsize=2, halign=\"left\"))\n",
    "Tk.set_size(ImageView.toplevel(imgc), 300, 300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on 100 and display on canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-Oct 14:24:59:INFO:root:Constructing net imagenet on Mocha.CPUBackend...\n",
      "20-Oct 14:24:59:INFO:root:Topological sorting 11 layers...\n",
      "20-Oct 14:24:59:INFO:root:Setup layers...\n",
      "20-Oct 14:24:59:INFO:root:Network constructed!\n",
      "20-Oct 14:24:59:INFO:root:Loading existing model from snapshots/snapshot-070000.jld\n",
      "20-Oct 14:24:59:DEBUG:root:Loading parameters for layer conv1\n",
      "20-Oct 14:24:59:DEBUG:root:Loading parameters for layer conv2\n",
      "20-Oct 14:24:59:DEBUG:root:Loading parameters for layer conv3\n",
      "20-Oct 14:24:59:DEBUG:root:Loading parameters for layer ip1\n",
      "Loading Tags...\n",
      "Running net forward for an 10 x 10 canvas...\n",
      "     Running column 10 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10x10 Array{Int64,2}:\n",
       "  8  0  2  0  0  0  0  0  0  0\n",
       "  9  3  2  0  0  0  0  0  0  0\n",
       "  3  0  5  0  0  0  0  0  0  0\n",
       "  6  0  3  2  0  0  0  0  0  0\n",
       "  6  0  3  0  0  0  0  0  0  0\n",
       "  1  0  3  0  0  0  0  0  0  0\n",
       "  6  1  5  0  0  0  0  0  0  0\n",
       "  3  0  3  0  0  0  0  0  0  1\n",
       "  9  0  1  0  0  0  0  0  1  0\n",
       " 11  1  1  0  0  0  0  0  0  1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Mocha, Images, ImageView, Colors, HDF5, MLBase\n",
    "\n",
    "#1. Load the trained network weights\n",
    "#2. Set up a loop to run the net forward and get an array of predictions\n",
    "#3.    Use MLBase to classify the prediction\n",
    "#4.    Load the tags and GT labels\n",
    "#5.    Use the tags and GT to annotate the image\n",
    "#6.    Add the image to a canvas\n",
    "\n",
    "using Mocha, Images, ImageView, Colors, HDF5, MLBase\n",
    "backend = CPUBackend()\n",
    "init(backend)\n",
    "\n",
    "image_x = 32\n",
    "image_y = 32\n",
    "image_depth = 3\n",
    "\n",
    "test_index = 12;\n",
    "\n",
    "#Create a memory data layer in the prediction model that we computation\n",
    "#sequentially tie to the next image we want to predict on.\n",
    "mem_data = MemoryDataLayer(name=\"data\", tops=[:data], batch_size=1,\n",
    "    data=Array[zeros(Float32, image_x, image_y, image_depth, 1)])\n",
    "\n",
    "#Copy over the rest of the layers from the training network\n",
    "conv1_layer = ConvolutionLayer(name=\"conv1\", n_filter=32, kernel=(5,5), pad=(2,2),\n",
    "    stride=(1,1), filter_init=GaussianInitializer(std=0.0001),\n",
    "    bottoms=[:data], tops=[:conv1])\n",
    "pool1_layer = PoolingLayer(name=\"pool1\", kernel=(3,3), stride=(2,2), neuron=Neurons.ReLU(),\n",
    "    bottoms=[:conv1], tops=[:pool1])\n",
    "norm1_layer = LRNLayer(name=\"norm1\", kernel=3, scale=5e-5, power=0.75, mode=LRNMode.WithinChannel(),\n",
    "    bottoms=[:pool1], tops=[:norm1])\n",
    "conv2_layer = ConvolutionLayer(name=\"conv2\", n_filter=32, kernel=(5,5), pad=(2,2),\n",
    "    stride=(1,1), filter_init=GaussianInitializer(std=0.01),\n",
    "    bottoms=[:norm1], tops=[:conv2], neuron=Neurons.ReLU())\n",
    "pool2_layer = PoolingLayer(name=\"pool2\", kernel=(3,3), stride=(2,2), pooling=Pooling.Mean(),\n",
    "    bottoms=[:conv2], tops=[:pool2])\n",
    "norm2_layer = LRNLayer(name=\"norm2\", kernel=3, scale=5e-5, power=0.75, mode=LRNMode.WithinChannel(),\n",
    "    bottoms=[:pool2], tops=[:norm2])\n",
    "conv3_layer = ConvolutionLayer(name=\"conv3\", n_filter=64, kernel=(5,5), pad=(2,2),\n",
    "    stride=(1,1), filter_init=GaussianInitializer(std=0.01),\n",
    "    bottoms=[:norm2], tops=[:conv3], neuron=Neurons.ReLU())\n",
    "pool3_layer = PoolingLayer(name=\"pool3\", kernel=(3,3), stride=(2,2), pooling=Pooling.Mean(),\n",
    "    bottoms=[:conv3], tops=[:pool3])\n",
    "ip1_layer   = InnerProductLayer(name=\"ip1\", output_dim=10, weight_init=GaussianInitializer(std=0.01),\n",
    "    weight_regu=L2Regu(250), bottoms=[:pool3], tops=[:ip1])\n",
    "\n",
    "#Instead of a SoftmaxLossLayer like the training script in this file we\n",
    "#have a pure SoftmaxLayer in order to determine the probability of the \n",
    "#image compared against the different n classification options\n",
    "softmax_layer = SoftmaxLayer(name=\"prob\", tops=[:prob], bottoms=[:ip1])\n",
    "\n",
    "#Build the network\n",
    "common_layers = [conv1_layer, pool1_layer, norm1_layer, conv2_layer, pool2_layer, norm2_layer,\n",
    "                 conv3_layer, pool3_layer, ip1_layer]\n",
    "run_net = Net(\"imagenet\", backend, [mem_data, common_layers..., softmax_layer])\n",
    "\n",
    "#Load the network snapshot from the training data\n",
    "load_snapshot(run_net, \"snapshots/snapshot-070000.jld\")\n",
    "\n",
    "#Now run one test through the network to ensure it is set up correctly\n",
    "fid = h5open(\"data/test.hdf5\", \"r\")\n",
    "features = read(fid, \"data\")\n",
    "labels = read(fid, \"label\")\n",
    "\n",
    "#Load the displayable images\n",
    "vis_fid = h5open(\"data/visual.hdf5\", \"r\")\n",
    "vis_data = read(vis_fid, \"data\")\n",
    "\n",
    "#Set up some constants used in the loop\n",
    "#set up the label location on the 32x32 image\n",
    "x1 = 4\n",
    "y1 = 30\n",
    "x2 = 4\n",
    "y2 = 3\n",
    "offset = 1  #my tags vector is 1-indexed but the labels vector is \n",
    "                  #is 0-indexed.  So I have to add an offset of 1 to the label value to \n",
    "                  # match my predictive value \n",
    "println(\"Loading Tags...\")\n",
    "tags = []\n",
    "fname = \"batches.meta.txt\"\n",
    "open(fname) do file\n",
    "    for line in eachline(file)\n",
    "        line = strip(line)\n",
    "        if length(line)>0 \n",
    "            push!(tags, strip(line))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "#Set canvas size\n",
    "N = 10\n",
    "#Create a canvas to paint on\n",
    "c = canvasgrid(N,N)\n",
    "font = round(N/2) # set fontsize relative to N\n",
    "\n",
    "#set up a list to capture results\n",
    "gts = []\n",
    "preds = []\n",
    "\n",
    "println(\"Running net forward for an $N x $N canvas...\")\n",
    "printed_flag = 0;\n",
    "for j in 1:N for k in 1:N\n",
    "    if j%10==0 && printed_flag != j\n",
    "        println(\"     Running column $j ...\") \n",
    "        printed_flag = j\n",
    "    end\n",
    "    #convert the j,k vals into a straight index\n",
    "    i = (j-1)*10 + k\n",
    "    #Load the ith image and label \n",
    "    get_layer(run_net, \"data\").data[1][:,:,image_depth,1] = features[:,:,image_depth,i]\n",
    "    gt = Int64(labels[i])+offset\n",
    "    push!(gts, gt)\n",
    "\n",
    "    # Run the net forward and use MLBase to classify the output blob\n",
    "    forward(run_net)\n",
    "    prediction = classify(run_net.output_blobs[:prob].data)\n",
    "    push!(preds, prediction[1])\n",
    "        \n",
    "    #create the visual image for the ith sample\n",
    "    img = convert(Image, vis_data[:,:,:,i])\n",
    "    img[\"spatialorder\"]=[\"x\",\"y\"]\n",
    "\n",
    "    #create the string label\n",
    "    l1 = string(\"GT: \", tags[gt])\n",
    "    l2 = string(\"Pred: \", tags[prediction[1]])\n",
    "\n",
    "    #annotate the image\n",
    "    c2, slice = ImageView.view(c[j,k], img)\n",
    "    idx = ImageView.annotate!(c2, slice, ImageView.AnnotationText(x1, y1, l1, color=RGB(1,0,0), fontsize=font, halign=\"left\"))\n",
    "    idx = ImageView.annotate!(c2, slice, ImageView.AnnotationText(x2, y2, l2, color=RGB(1,0,0), fontsize=font, halign=\"left\"))\n",
    "  end\n",
    "end\n",
    "#    Tk.set_size(ImageView.toplevel(imgc), 300, 300)\n",
    "\n",
    "gts = convert(Array{Int64}, gts)\n",
    "preds = convert(Array{Int64}, preds)\n",
    "confusmat(10, gts, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build confusion matrix for all tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-Oct 16:22:28:INFO:root:Constructing net imagenet on Mocha.CPUBackend...\n",
      "20-Oct 16:22:28:INFO:root:Topological sorting 11 layers...\n",
      "20-Oct 16:22:28:INFO:root:Setup layers...\n",
      "20-Oct 16:22:28:INFO:root:Network constructed!\n",
      "20-Oct 16:22:28:INFO:root:Loading existing model from snapshots/snapshot-070000.jld\n",
      "20-Oct 16:22:28:DEBUG:root:Loading parameters for layer conv1\n",
      "20-Oct 16:22:28:DEBUG:root:Loading parameters for layer conv2\n",
      "20-Oct 16:22:28:DEBUG:root:Loading parameters for layer conv3\n",
      "20-Oct 16:22:28:DEBUG:root:Loading parameters for layer ip1\n",
      "Loading Tags...\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "LoadError: SystemError: opening file batches.meta.txt: No such file or directory\nwhile loading In[17], in expression starting on line 80",
     "output_type": "error",
     "traceback": [
      "LoadError: SystemError: opening file batches.meta.txt: No such file or directory\nwhile loading In[17], in expression starting on line 80",
      "",
      " in open at /Applications/Julia-0.4.6.app/Contents/Resources/julia/lib/julia/sys.dylib (repeats 2 times)"
     ]
    }
   ],
   "source": [
    "using Mocha, Images, ImageView, Colors, HDF5, MLBase\n",
    "\n",
    "#1. Load the trained network weights\n",
    "#2. Set up a loop to run the net forward and get an array of predictions\n",
    "#3.    Use MLBase to classify the prediction\n",
    "#4.    Load the tags and GT labels\n",
    "#5.    Use the tags and GT to annotate the image\n",
    "#6.    Add the image to a canvas\n",
    "\n",
    "backend = CPUBackend()\n",
    "init(backend)\n",
    "\n",
    "image_x = 32\n",
    "image_y = 32\n",
    "image_depth = 3\n",
    "\n",
    "#Create a memory data layer in the prediction model that we computation\n",
    "#sequentially tie to the next image we want to predict on.\n",
    "mem_data = MemoryDataLayer(name=\"data\", tops=[:data], batch_size=1,\n",
    "    data=Array[zeros(Float32, image_x, image_y, image_depth, 1)])\n",
    "\n",
    "#Copy over the rest of the layers from the training network\n",
    "conv1_layer = ConvolutionLayer(name=\"conv1\", n_filter=32, kernel=(5,5), pad=(2,2),\n",
    "    stride=(1,1), filter_init=GaussianInitializer(std=0.0001),\n",
    "    bottoms=[:data], tops=[:conv1])\n",
    "pool1_layer = PoolingLayer(name=\"pool1\", kernel=(3,3), stride=(2,2), neuron=Neurons.ReLU(),\n",
    "    bottoms=[:conv1], tops=[:pool1])\n",
    "norm1_layer = LRNLayer(name=\"norm1\", kernel=3, scale=5e-5, power=0.75, mode=LRNMode.WithinChannel(),\n",
    "    bottoms=[:pool1], tops=[:norm1])\n",
    "conv2_layer = ConvolutionLayer(name=\"conv2\", n_filter=32, kernel=(5,5), pad=(2,2),\n",
    "    stride=(1,1), filter_init=GaussianInitializer(std=0.01),\n",
    "    bottoms=[:norm1], tops=[:conv2], neuron=Neurons.ReLU())\n",
    "pool2_layer = PoolingLayer(name=\"pool2\", kernel=(3,3), stride=(2,2), pooling=Pooling.Mean(),\n",
    "    bottoms=[:conv2], tops=[:pool2])\n",
    "norm2_layer = LRNLayer(name=\"norm2\", kernel=3, scale=5e-5, power=0.75, mode=LRNMode.WithinChannel(),\n",
    "    bottoms=[:pool2], tops=[:norm2])\n",
    "conv3_layer = ConvolutionLayer(name=\"conv3\", n_filter=64, kernel=(5,5), pad=(2,2),\n",
    "    stride=(1,1), filter_init=GaussianInitializer(std=0.01),\n",
    "    bottoms=[:norm2], tops=[:conv3], neuron=Neurons.ReLU())\n",
    "pool3_layer = PoolingLayer(name=\"pool3\", kernel=(3,3), stride=(2,2), pooling=Pooling.Mean(),\n",
    "    bottoms=[:conv3], tops=[:pool3])\n",
    "ip1_layer   = InnerProductLayer(name=\"ip1\", output_dim=10, weight_init=GaussianInitializer(std=0.01),\n",
    "    weight_regu=L2Regu(250), bottoms=[:pool3], tops=[:ip1])\n",
    "\n",
    "#Instead of a SoftmaxLossLayer like the training script in this file we\n",
    "#have a pure SoftmaxLayer in order to determine the probability of the \n",
    "#image compared against the different n classification options\n",
    "softmax_layer = SoftmaxLayer(name=\"prob\", tops=[:prob], bottoms=[:ip1])\n",
    "\n",
    "#Build the network\n",
    "common_layers = [conv1_layer, pool1_layer, norm1_layer, conv2_layer, pool2_layer, norm2_layer,\n",
    "                 conv3_layer, pool3_layer, ip1_layer]\n",
    "run_net = Net(\"imagenet\", backend, [mem_data, common_layers..., softmax_layer])\n",
    "\n",
    "#Load the network snapshot from the training data\n",
    "load_snapshot(run_net, \"snapshots/snapshot-070000.jld\")\n",
    "\n",
    "#Now run one test through the network to ensure it is set up correctly\n",
    "fid = h5open(\"data/test.hdf5\", \"r\")\n",
    "features = read(fid, \"data\")\n",
    "labels = read(fid, \"label\")\n",
    "\n",
    "#Load the displayable images\n",
    "vis_fid = h5open(\"data/visual.hdf5\", \"r\")\n",
    "vis_data = read(vis_fid, \"data\")\n",
    "\n",
    "#Set up some constants used in the loop\n",
    "#set up the label location on the 32x32 image\n",
    "N = 1000 # number of samples\n",
    "x1 = 4\n",
    "y1 = 30\n",
    "x2 = 4\n",
    "y2 = 3\n",
    "offset = 1  #my tags vector is 1-indexed but the labels vector is \n",
    "                  #is 0-indexed.  So I have to add an offset of 1 to the label value to \n",
    "                  # match my predictive value \n",
    "println(\"Loading Tags...\")\n",
    "tags = []\n",
    "fname = \"batches.meta.txt\"\n",
    "open(fname) do file\n",
    "    for line in eachline(file)\n",
    "        line = strip(line)\n",
    "        if length(line)>0 \n",
    "            push!(tags, strip(line))\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "#set up a list to capture results\n",
    "gts = []\n",
    "preds = []\n",
    "\n",
    "printed_flag = 0;\n",
    "for j in 1:N\n",
    "    if j%100==0\n",
    "        println(\"     Running iteration $j ...\") \n",
    "    end\n",
    " \n",
    "    #Load the jth image and label \n",
    "    get_layer(run_net, \"data\").data[1][:,:,image_depth,1] = features[:,:,image_depth,j]\n",
    "    gt = Int64(labels[j])+offset\n",
    "    push!(gts, gt)\n",
    "\n",
    "    # Run the net forward and use MLBase to classify the output blob\n",
    "    forward(run_net)\n",
    "    prediction = classify(run_net.output_blobs[:prob].data)\n",
    "    push!(preds, prediction[1])\n",
    "        \n",
    "end\n",
    "#    Tk.set_size(ImageView.toplevel(imgc), 300, 300)\n",
    "\n",
    "gts = convert(Array{Int64}, gts)\n",
    "preds = convert(Array{Int64}, preds)\n",
    "println(correctrate(gts, preds))\n",
    "confusmat(10, gts, preds)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.4.6",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
