{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the prediction and show the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using Mocha\n",
    "\n",
    "backend = CPUBackend()\n",
    "init(backend)\n",
    "\n",
    "#Create a memory data layer in the prediction model that we computation\n",
    "#sequentially tie to the next image we want to predict on.\n",
    "mem_data = MemoryDataLayer(name=\"data\", tops=[:data], batch_size=1,\n",
    "  data=Array[zeros(Float32, 28, 28, 1, 1)])\n",
    "\n",
    "#Create the network with two conv/pooling layers and two fully\n",
    "#connected inner product layers\n",
    "conv_layer = ConvolutionLayer(name=\"conv1\", n_filter=20, kernel=(5,5),\n",
    "  bottoms=[:data], tops=[:conv1])\n",
    "pool_layer = PoolingLayer(name=\"pool1\", kernel=(2,2), stride=(2,2),\n",
    "  bottoms=[:conv1], tops=[:pool1])\n",
    "conv2_layer = ConvolutionLayer(name=\"conv2\", n_filter=20, kernel=(5,5),\n",
    "  bottoms=[:pool1], tops=[:conv2])\n",
    "pool2_layer = PoolingLayer(name=\"pool2\", kernel=(2,2), stride  = (2,2),\n",
    "  bottoms=[:conv2], tops=[:pool2])\n",
    "fc1_layer = InnerProductLayer(name=\"ip1\", output_dim=500,\n",
    "  neuron=Neurons.ReLU(), bottoms=[:pool2], tops=[:ip1])\n",
    "fc2_layer = InnerProductLayer(name=\"ip2\", output_dim=10,\n",
    "  bottoms=[:ip1], tops=[:ip2])\n",
    "\n",
    "#Instead of a SoftmaxLossLayer like the training script in this file we\n",
    "#have a pure SoftmaxLayer in order to determine the probability of the \n",
    "#image compared against the different n classification options\n",
    "softmax_layer = SoftmaxLayer(name=\"prob\", tops=[:prob], bottoms=[:ip2])\n",
    "\n",
    "#Build the network\n",
    "common_layers = [conv_layer, pool_layer, conv2_layer, pool2_layer,\n",
    "  fc1_layer, fc2_layer]\n",
    "run_net = Net(\"imagenet\", backend, [mem_data, common_layers..., softmax_layer])\n",
    "\n",
    "#Load the latest snapshot from the training data\n",
    "load_snapshot(run_net, \"snapshots_bak/snapshot-010000.jld\")\n",
    "\n",
    "#Now load one image and run it through the network\n",
    "using HDF5, ImageView, Images\n",
    "fid = h5open(\"data/test.hdf5\", \"r\")\n",
    "features = read(fid, \"data\")\n",
    "labels = read(fid, \"label\")\n",
    "\n",
    "get_layer(run_net, \"data\").data[1][:,:,1,1] = features[:,:,1,1]\n",
    "\n",
    "println(\"\\nCorrect label index: \", Int64(labels[:,1][1]))\n",
    "\n",
    "forward(run_net)\n",
    "println()\n",
    "println(\"Label prob vector:\")\n",
    "println(run_net.output_blobs[:prob].data)\n",
    "\n",
    "using MLBase\n",
    "offset = -1  #my prediction vector is 1-based as opposed to the label\n",
    "             #set which is 0-based.  So this offset matches them\n",
    "prediction = classify(run_net.output_blobs[:prob].data) + offset\n",
    "println(\"Prediction is: \", prediction[:][1])\n",
    "\n",
    "#destroy the net\n",
    "destroy(run_net)\n",
    "shutdown(backend)\n",
    "\n",
    "# Show the digit\n",
    "A = features[:,:,1,1]\n",
    "digit = convert(Image, A)\n",
    "#default spatialorder is yx\n",
    "digit[\"spatialorder\"] = [\"x\", \"y\"]\n",
    "digit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the net 10 times and show the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring Mocha...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition info(Any...) in module Base at util.jl:334 overwritten in module Logging at /Users/admin/.julia/v0.4/Logging/src/Logging.jl:61.\n",
      "WARNING: Method definition warn(Any...) in module Base at util.jl:364 overwritten in module Logging at /Users/admin/.julia/v0.4/Logging/src/Logging.jl:61.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * CUDA       disabled by default\n",
      " * Native Ext disabled by default\n",
      "Mocha configured, continue loading module...\n",
      "DefaultBackend = Mocha.CPUBackend\n",
      "11-Oct 19:53:03:INFO:root:Constructing net imagenet on Mocha.CPUBackend...\n",
      "11-Oct 19:53:03:INFO:root:Topological sorting 8 layers...\n",
      "11-Oct 19:53:03:INFO:root:Setup layers...\n",
      "11-Oct 19:53:05:INFO:root:Network constructed!\n",
      "11-Oct 19:53:08:INFO:root:Loading existing model from snapshots_bak/snapshot-010000.jld\n",
      "11-Oct 19:53:11:DEBUG:root:Loading parameters for layer conv1\n",
      "11-Oct 19:53:11:DEBUG:root:Loading parameters for layer conv2\n",
      "11-Oct 19:53:11:DEBUG:root:Loading parameters for layer ip1\n",
      "11-Oct 19:53:11:DEBUG:root:Loading parameters for layer ip2\n",
      "Sample 1 is: 4==>4\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 2 is: 2==>2\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 3 is: 6==>6\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 4 is: 6==>6\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 5 is: 2==>2\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 6 is: 9==>9\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 7 is: 4==>4\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 8 is: 0==>0\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 9 is: 5==>5\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 10 is: 8==>8\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 11 is: 6==>6\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 12 is: 4==>4\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 13 is: 7==>7\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 14 is: 6==>6\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 15 is: 9==>9\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 16 is: 2==>2\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 17 is: 8==>8\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 18 is: 8==>8\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 19 is: 0==>0\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 20 is: 6==>6\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 21 is: 6==>6\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 22 is: 2==>2\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 23 is: 5==>5\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 24 is: 4==>4\n",
      "Press the Enter key to continue:STDIN> \n",
      "Sample 25 is: 6==>6\n",
      "Press the Enter key to continue:STDIN> \n",
      "******* TEST COMPLETE ********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: both ImageView and Mocha export \"destroy\"; uses of it in module Main must be qualified\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: destroy not defined\nwhile loading In[1], in expression starting on line 95",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: destroy not defined\nwhile loading In[1], in expression starting on line 95",
      ""
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "`input(prompt::AbstractString=\"\")`\n",
    "\n",
    "Read a string from STDIN. The trailing newline is stripped.\n",
    "\n",
    "The prompt string, if given, is printed to standard output without a\n",
    "trailing newline before reading input.\n",
    "\"\"\"\n",
    "function input(prompt::AbstractString=\"\")\n",
    "   print(prompt)\n",
    "   return chomp(readline())\n",
    "end\n",
    "\n",
    "using Mocha\n",
    "\n",
    "backend = CPUBackend()\n",
    "init(backend)\n",
    "\n",
    "#Create a memory data layer in the prediction model that we computation\n",
    "#sequentially tie to the next image we want to predict on.\n",
    "mem_data = MemoryDataLayer(name=\"data\", tops=[:data], batch_size=1,\n",
    "  data=Array[zeros(Float32, 28, 28, 1, 1)])\n",
    "\n",
    "#Create the network with two conv/pooling layers and two fully\n",
    "#connected inner product layers\n",
    "conv_layer = ConvolutionLayer(name=\"conv1\", n_filter=20, kernel=(5,5),\n",
    "  bottoms=[:data], tops=[:conv1])\n",
    "pool_layer = PoolingLayer(name=\"pool1\", kernel=(2,2), stride=(2,2),\n",
    "  bottoms=[:conv1], tops=[:pool1])\n",
    "conv2_layer = ConvolutionLayer(name=\"conv2\", n_filter=20, kernel=(5,5),\n",
    "  bottoms=[:pool1], tops=[:conv2])\n",
    "pool2_layer = PoolingLayer(name=\"pool2\", kernel=(2,2), stride  = (2,2),\n",
    "  bottoms=[:conv2], tops=[:pool2])\n",
    "fc1_layer = InnerProductLayer(name=\"ip1\", output_dim=500,\n",
    "  neuron=Neurons.ReLU(), bottoms=[:pool2], tops=[:ip1])\n",
    "fc2_layer = InnerProductLayer(name=\"ip2\", output_dim=10,\n",
    "  bottoms=[:ip1], tops=[:ip2])\n",
    "\n",
    "#Instead of a SoftmaxLossLayer like the training script in this file we\n",
    "#have a pure SoftmaxLayer in order to determine the probability of the \n",
    "#image compared against the different n classification options\n",
    "softmax_layer = SoftmaxLayer(name=\"prob\", tops=[:prob], bottoms=[:ip2])\n",
    "\n",
    "#Build the network\n",
    "common_layers = [conv_layer, pool_layer, conv2_layer, pool2_layer,\n",
    "  fc1_layer, fc2_layer]\n",
    "run_net = Net(\"imagenet\", backend, [mem_data, common_layers..., softmax_layer])\n",
    "\n",
    "#Load the latest snapshot from the training data\n",
    "load_snapshot(run_net, \"snapshots_bak/snapshot-010000.jld\")\n",
    "\n",
    "#Open the data source and load the features and labels\n",
    "using HDF5, MLBase, ImageView, Images\n",
    "fid = h5open(\"data/test.hdf5\", \"r\")\n",
    "features = read(fid, \"data\")\n",
    "labels = read(fid, \"label\")[:] #put the labels into a single vector\n",
    "\n",
    "offset = -1 #my prediction vector is 1-indexed as opposed to the label\n",
    "            #set which is 0-indexed.  So this offset matches them\n",
    "\n",
    "#load the initial image to get the handle to the canvas\n",
    "A1 = features[:,:,1,1]\n",
    "digit = convert(Image, A1)\n",
    "digit[\"spatialorder\"]=[\"x\", \"y\"]\n",
    "imgc, imgs = view(digit)\n",
    "Tk.set_size(ImageView.toplevel(imgc), 200, 200)\n",
    "\n",
    "#set up the loop\n",
    "for i in 1:25\n",
    "    #load the data into the layer\n",
    "    get_layer(run_net, \"data\").data[1][:,:,1,1] = features[:,:,1,i]\n",
    "    forward(run_net)\n",
    "    prediction = classify(run_net.output_blobs[:prob].data) + offset\n",
    "    prediction = prediction[:][1]\n",
    "    gt = convert(Int64, labels[i])\n",
    "    println(\"Sample $i is: $gt==>$prediction\")\n",
    "    \n",
    "    #show the image\n",
    "    A = features[:,:,1,i]\n",
    "    digit = convert(Image, A)\n",
    "    #default spatialorder is yx\n",
    "    digit[\"spatialorder\"] = [\"x\", \"y\"]\n",
    "    view(imgc, digit)\n",
    "    \n",
    "    #pause for Enter\n",
    "    input(\"Press the Enter key to continue:\")\n",
    "    #pause for 1/2 second\n",
    "    #sleep(1.0)\n",
    "    \n",
    "end\n",
    "\n",
    "println(\"******* TEST COMPLETE ********\")\n",
    "\n",
    "#destroy the net\n",
    "Mocha.destroy(run_net)\n",
    "Mocha.shutdown(backend)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.4.6",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
